{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Algorithm Performance Metrics\n",
    "\n",
    "><small><i>from the book \n",
    "\"Machine Learning Mastery With Python: Understand Your Data, Create Accurate Models and Work Projects End-To-End\"\n",
    "by Jason Brownlee, Migrated to Jupyter with additions by Mitch Sanders 2017</i></small>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics that you choose to evaluate your machine learning algorithms are very important.\n",
    "Choice of metrics influences how the performance of machine learning algorithms is measured\n",
    "and compared. They influence how you weight the importance of different characteristics in\n",
    "the results and your ultimate choice of which algorithm to choose. In this chapter you will\n",
    "discover how to select and use different machine learning performance metrics in Python with\n",
    "scikit-learn. Let’s get started.\n",
    "\n",
    "## Algorithm Evaluation Metrics\n",
    "In this lesson, various algorithm evaluation metrics are demonstrated for both classification and\n",
    "regression type machine learning problems. In each recipe, the dataset is downloaded directly\n",
    "from the UCI Machine Learning repository.\n",
    "- For **classification** metrics, the Pima Indians onset of diabetes dataset is used as demonstration. This is a binary classification problem where all of the input variables are numeric.\n",
    "- For **regression** metrics, the Boston House Price dataset is used as demonstration. this is a regression problem where all of the input variables are also numeric.\n",
    "\n",
    "All recipes evaluate the same algorithms, Logistic Regression for classification and Linear\n",
    "Regression for the regression problems. A 10-fold cross-validation test harness is used to\n",
    "demonstrate each metric, because this is the most likely scenario you will use when employing\n",
    "different algorithm evaluation metrics.\n",
    "\n",
    "A caveat in these recipes is the cross validation.cross val score function used to\n",
    "report the performance in each recipe. It does allow the use of different scoring metrics\n",
    "that will be discussed, but all scores are reported so that they can be sorted in ascending\n",
    "order (**largest score is best**). Some evaluation metrics (like mean squared error) are naturally\n",
    "descending scores (*the smallest score is best*) and as such are reported as negative by the cross validation.cross val score() function. <u>This is important to note</u>, because some\n",
    "scores will be reported as negative that by definition can never be negative. I will remind you\n",
    "about this caveat as we work through the lesson.\n",
    "\n",
    "You can learn more about machine learning algorithm performance metrics supported by\n",
    "scikit-learn on the page *Model evaluation: quantifying the quality of predictions*. \n",
    "\n",
    "http://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.cross_val_score.html\n",
    "\n",
    "Let’s get on with the evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Metrics\n",
    "Classification problems are perhaps the most common type of machine learning problem and as\n",
    "such there are a myriad of metrics that can be used to evaluate predictions for these problems.\n",
    "In this section we will review how to use the following metrics:\n",
    "- Classification Accuracy.\n",
    "- Logarithmic Loss.\n",
    "- Area Under ROC Curve.\n",
    "- Confusion Matrix.\n",
    "- Classification Report.\n",
    "\n",
    "### Classification Accuracy\n",
    "Classification accuracy is the number of correct predictions made as a ratio of all predictions\n",
    "made. This is the most common evaluation metric for classification problems, **it is also the most\n",
    "misused**. It is really only suitable when there are an equal number of observations in each class\n",
    "(which is rarely the case) and that **all predictions and prediction errors are equally important**,\n",
    "which is often not the case. Below is an example of calculating classification accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.95% (0.048)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification Accuracy\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LogisticRegression()\n",
    "scoring = 'accuracy'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"Accuracy: %.2f%% (%.3f)\") % (results.mean()*100, results.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the ratio is reported. This can be converted into a percentage by multiplying\n",
    "the value by 100, giving an accuracy score of approximately 77% accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logarithmic Loss\n",
    "Logarithmic loss (or logloss) is a performance metric for evaluating the predictions of probabilities\n",
    "of membership to a given class. The scalar probability between 0 and 1 can be seen as a measure\n",
    "of confidence for a prediction by an algorithm. Predictions that are correct or incorrect are\n",
    "rewarded or punished proportionally to the confidence of the prediction. Below is an example\n",
    "of calculating logloss for Logistic regression predictions on the Pima Indians onset of diabetes\n",
    "dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logloss: -0.493 (0.047)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification LogLoss\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LogisticRegression()\n",
    "scoring = 'neg_log_loss'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"Logloss: %.3f (%.3f)\") % (results.mean(), results.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smaller logloss is better with 0 representing a perfect logloss. As mentioned above, the\n",
    "measure is inverted to be ascending when using the cross val score() function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area Under ROC Curve\n",
    "Area under ROC Curve (or AUC for short) is a performance metric for binary classification\n",
    "problems. The AUC represents a model’s ability to discriminate between positive and negative\n",
    "classes. An area of 1.0 represents a model that made all predictions perfectly. An area of\n",
    "0.5 represents a model that is as good as random. ROC can be broken down into sensitivity\n",
    "and specificity. A binary classification problem is really a trade-off between sensitivity and\n",
    "specificity.\n",
    "\n",
    "- **Sensitivity** is the true positive rate also called the recall. It is the number of instances from the positive (first) class that actually predicted correctly.\n",
    "- **Specificity** is also called the true negative rate. Is the number of instances from the negative (second) class that were actually predicted correctly.\n",
    "\n",
    "The example below provides a demonstration of calculating AUC.\n",
    "\n",
    "Note* Sensitivity = Recall (synonyms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.824 (0.041)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification ROC AUC\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LogisticRegression()\n",
    "scoring = 'roc_auc'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"AUC: %.3f (%.3f)\") % (results.mean(), results.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the AUC is relatively close to 1 and greater than 0.5, suggesting some skill in\n",
    "the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "The confusion matrix is a handy presentation of the accuracy of a model with two or more\n",
    "classes. The table presents predictions on the x-axis and accuracy outcomes on the y-axis. The\n",
    "cells of the table are the number of predictions made by a machine learning algorithm. For\n",
    "example, a machine learning algorithm can predict 0 or 1 and each prediction may actually have\n",
    "been a 0 or 1. Predictions for 0 that were actually 0 appear in the cell for prediction = 0 and\n",
    "actual = 0, whereas predictions for 0 that were actually 1 appear in the cell for prediction = 0\n",
    "and actual = 1. And so on. Below is an example of calculating a confusion matrix for a set of\n",
    "predictions by a Logistic Regression on the Pima Indians onset of diabetes dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/confusionMatrix.png'></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[141  21]\n",
      " [ 41  51]]\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification Confusion Matrix\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "matrix = confusion_matrix(Y_test, predicted)\n",
    "print(matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report\n",
    "The scikit-learn library provides a convenience report when working on classification problems\n",
    "to give you a quick idea of the accuracy of a model using a number of measures. The\n",
    "classification report() function displays the precision, recall, F1-score and support for each\n",
    "class. The example below demonstrates the report on the binary classification problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.77      0.87      0.82       162\n",
      "        1.0       0.71      0.55      0.62        92\n",
      "\n",
      "avg / total       0.75      0.76      0.75       254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification Report\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "report = classification_report(Y_test, predicted)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see good prediction and recall for the algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Metrics\n",
    "In this section will review 3 of the most common metrics for evaluating predictions on regression\n",
    "machine learning problems:\n",
    "- Mean Absolute Error.\n",
    "- Mean Squared Error.\n",
    "- R2.\n",
    "\n",
    "### Mean Absolute Error\n",
    "The Mean Absolute Error (or MAE) is the sum of the absolute differences between predictions\n",
    "and actual values. It gives an idea of how wrong the predictions were. The measure gives an\n",
    "idea of the magnitude of the error, but no idea of the direction (e.g. over or under predicting).\n",
    "The example below demonstrates calculating mean absolute error on the Boston house price\n",
    "dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cross Validation Regression MAE\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "filename = 'housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LinearRegression()\n",
    "scoring = 'neg_mean_absolute_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"MAE: %.3f (%.3f)\") % (results.mean(), results.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A value of 0 indicates no error or perfect predictions. Like logloss, this metric is inverted by\n",
    "the cross val score() function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error\n",
    "The Mean Squared Error (or MSE) is much like the mean absolute error in that it provides a\n",
    "gross idea of the magnitude of error. Taking the square root of the mean squared error converts\n",
    "the units back to the original units of the output variable and can be meaningful for description\n",
    "and presentation. This is called the Root Mean Squared Error (or RMSE). The example below\n",
    "provides a demonstration of calculating mean squared error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cross Validation Regression MSE\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "filename = 'housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LinearRegression()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"MSE: %.3f (%.3f)\") % (results.mean(), results.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This metric too is inverted so that the results are increasing. Remember to take the absolute\n",
    "value before taking the square root if you are interested in calculating the RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R2 Metric\n",
    "The R2 (or R Squared) metric provides an indication of the goodness of fit of a set of predictions\n",
    "to the actual values. In statistical literature this measure is called the coefficient of determination.\n",
    "\n",
    "This is a value between 0 and 1 for no-fit and perfect fit respectively. The example below\n",
    "provides a demonstration of calculating the mean R2\n",
    "for a set of predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cross Validation Regression R^2\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "filename = 'housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LinearRegression()\n",
    "scoring = 'r2'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"R^2: %.3f (%.3f)\") % (results.mean(), results.std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the predictions have a poor fit to the actual values with a value closer to zero\n",
    "and less than 0.5.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Summary\n",
    "In this chapter you discovered metrics that you can use to evaluate your machine learning\n",
    "algorithms.\n",
    "You learned about three classification metrics: Accuracy, Logarithmic Loss and Area Under\n",
    "ROC Curve. You also learned about two convenience methods for classification prediction\n",
    "results: the Confusion Matrix and the Classification Report. Finally, you also learned about\n",
    "three metrics for regression problems: Mean Absolute Error, Mean Squared Error and R2.\n",
    "\n",
    "### Next\n",
    "You now know how to evaluate the performance of machine learning algorithms using a variety\n",
    "of different metrics and how to use those metrics to estimate the performance of algorithms on\n",
    "new unseen data using resampling. In the next lesson you will start looking at machine learning\n",
    "algorithms themselves, starting with classification techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "\n",
    "### About the Boston House Price dataset:\n",
    "Maintained at UCI machine Learning Repository\n",
    "https://archive.ics.uci.edu/ml/datasets/housing\n",
    "\n",
    "Included in scikit-learn datasets module\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html\n",
    "\n",
    "\n",
    "#### Attribute Information:\n",
    "\n",
    "1. CRIM: per capita crime rate by town \n",
    "2. ZN: proportion of residential land zoned for lots over 25,000 sq.ft. \n",
    "3. INDUS: proportion of non-retail business acres per town \n",
    "4. CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) \n",
    "5. NOX: nitric oxides concentration (parts per 10 million) \n",
    "6. RM: average number of rooms per dwelling \n",
    "7. AGE: proportion of owner-occupied units built prior to 1940 \n",
    "8. DIS: weighted distances to five Boston employment centres \n",
    "9. RAD: index of accessibility to radial highways \n",
    "10. TAX: full-value property-tax rate per 10,000 US Dollars\n",
    "11. PTRATIO: pupil-teacher ratio by town \n",
    "12. B: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town \n",
    "13. LSTAT: % lower status of the population \n",
    "14. MEDV: Median value of owner-occupied homes in 1000's US Dollars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# demo using Boston Housing data in SciKit-learn\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print(boston.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the Pima Indian Dataset \n",
    "\n",
    "#### Attribute Information:\n",
    "\n",
    "1. Number of times pregnant \n",
    "2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test \n",
    "3. Diastolic blood pressure (mm Hg) \n",
    "4. Triceps skin fold thickness (mm) \n",
    "5. 2-Hour serum insulin (mu U/ml) \n",
    "6. Body mass index (weight in kg/(height in m)^2) \n",
    "7. Diabetes pedigree function \n",
    "8. Age (years) \n",
    "9. Class variable (0 or 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional notes on a Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Q: What is the best way to understand the terms \"precision\" and \"recall\"?\n",
    "- A:  \n",
    "    - Recall:  correctly predicted 1's / all 1's = TP / (TP + FN); \n",
    "    - Precision: correctly  predicted 1's / all predicted 1's = TP / (TP+FP)\n",
    "\n",
    "Reference links: \n",
    "\n",
    "- https://www.quora.com/What-is-the-best-way-to-understand-the-terms-precision-and-recall\n",
    "- https://classeval.wordpress.com/introduction/basic-evaluation-measures/\n",
    "- http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/\n",
    " \n",
    "You can learn most all you need to learn it from this link.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_confusion_matrix(C,class_labels=['0','1']):\n",
    "    \"\"\"\n",
    "    # http://notmatthancock.github.io/2015/10/28/confusion-matrix.html\n",
    "    # source has ERRORS in definitions - corrected here by Mitch Sanders 6/28/2017\n",
    "    \n",
    "    C: ndarray, shape (2,2) as given by scikit-learn confusion_matrix function\n",
    "    class_labels: list of strings, default simply labels 0 and 1.\n",
    "\n",
    "    Draws confusion matrix with associated metrics.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    assert C.shape == (2,2), \"Confusion matrix should be from binary classification only.\"\n",
    "    \n",
    "    # true negative, false positive, etc...\n",
    "    tn = C[0,0]; fp = C[0,1]; fn = C[1,0]; tp = C[1,1];\n",
    "\n",
    "    NP = fn+tp # Num positive examples\n",
    "    NN = tn+fp # Num negative examples\n",
    "    N  = NP+NN\n",
    "\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax  = fig.add_subplot(111)\n",
    "    ax.imshow(C, interpolation='nearest', cmap=plt.cm.gray)\n",
    "\n",
    "    # Draw the grid boxes\n",
    "    ax.set_xlim(-0.5,2.5)\n",
    "    ax.set_ylim(2.5,-0.5)\n",
    "    ax.plot([-0.5,2.5],[0.5,0.5], '-k', lw=2)\n",
    "    ax.plot([-0.5,2.5],[1.5,1.5], '-k', lw=2)\n",
    "    ax.plot([0.5,0.5],[-0.5,2.5], '-k', lw=2)\n",
    "    ax.plot([1.5,1.5],[-0.5,2.5], '-k', lw=2)\n",
    "\n",
    "    # Set xlabels\n",
    "    ax.set_xlabel('Predicted Label', fontsize=16)\n",
    "    ax.set_xticks([0,1,2])\n",
    "    ax.set_xticklabels(class_labels + [''])\n",
    "    ax.xaxis.set_label_position('top')\n",
    "    ax.xaxis.tick_top()\n",
    "    # These coordinate might require some tinkering. Ditto for y, below.\n",
    "    ax.xaxis.set_label_coords(0.34,1.06)\n",
    "\n",
    "    # Set ylabels\n",
    "    ax.set_ylabel('True Label', fontsize=16, rotation=90)\n",
    "    ax.set_yticklabels(class_labels + [''],rotation=90)\n",
    "    ax.set_yticks([0,1,2])\n",
    "    ax.yaxis.set_label_coords(-0.09,0.65)\n",
    "\n",
    "\n",
    "    # Fill in initial metrics: tp, tn, etc...\n",
    "    ax.text(0,0,\n",
    "            'True Neg: %d\\n(Num Neg: %d)'%(tn,NN),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(0,1,\n",
    "            'False Neg: %d'%fn,\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(1,0,\n",
    "            'False Pos: %d'%fp,\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "\n",
    "    ax.text(1,1,\n",
    "            'True Pos: %d\\n(Num Pos: %d)'%(tp,NP),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    # Fill in secondary metrics: accuracy, true pos rate, etc...\n",
    "    ax.text(2,0,\n",
    "            'True Neg Rate: %.2f %%\\n[Specificity]\\n(TN / (TN + FP))' % (tn / (fp+tn+0.)*100),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(2,1,\n",
    "            'True Pos Rate: %.2f %%\\n[Recall, Sensitivity]\\nTP / (TP + FN)'%(tp / (tp+fn+0.)*100),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(2,2,\n",
    "            'Accuracy: %.2f %%'%((tp+tn+0.)/N*100),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(0,2,\n",
    "            'Neg Pred Val: %.2f %%\\nTN / (TN + FN)'%(tn/(fn+tn+0.)*100),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(1,2,\n",
    "            'Pos Pred Val: %.2f %%\\n[Precision]\\nTP / (TP + FP)'%(tp/(tp+fp+0.)*100),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a little nicer visualization from \n",
    "# http://notmatthancock.github.io/2015/10/28/confusion-matrix.html\n",
    "# function is below.... run first before calling here \n",
    "C = confusion_matrix(Y_test, predicted)\n",
    "show_confusion_matrix(C, ['Class 0', 'Class 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrojrGfYkHgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcb55e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# demo on AUC visualization on Iris dataset\n",
    "\n",
    "# print(__doc__)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "# Import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Binarize the output\n",
    "y = label_binarize(y, classes=[0, 1, 2])\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "# Add noisy features to make the problem harder\n",
    "random_state = np.random.RandomState(0)\n",
    "n_samples, n_features = X.shape\n",
    "X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]\n",
    "\n",
    "# shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Learn to predict each class against the other\n",
    "classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,\n",
    "                                 random_state=random_state))\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Plot of a ROC curve for a specific class\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
