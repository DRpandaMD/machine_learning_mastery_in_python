{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automate Machine Learning Workflows with Pipelines\n",
    "\n",
    "><small><i>from the book \n",
    "\"Machine Learning Mastery With Python: Understand Your Data, Create Accurate Models and Work Projects End-To-End\"\n",
    "by Jason Brownlee, Migrated to Jupyter with additions by Mitch Sanders 2017</i></small>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are standard workflows in a machine learning project that can be automated. In Python\n",
    "scikit-learn, Pipelines help to clearly define and automate these workflows. In this chapter you\n",
    "will discover Pipelines in scikit-learn and how you can automate common machine learning\n",
    "workflows. After completing this lesson you will know:\n",
    "\n",
    "1. How to use pipelines to minimize data leakage.\n",
    "2. How to construct a data preparation and modeling pipeline.\n",
    "3. How to construct a feature extraction and modeling pipeline.\n",
    "\n",
    "Letâ€™s get started.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automating Machine Learning Workflows\n",
    "\n",
    "There are standard workflows in applied machine learning. Standard because they overcome\n",
    "common problems like data leakage in your test harness. Python scikit-learn provides a Pipeline\n",
    "utility to help automate machine learning workflows. Pipelines work by allowing for a linear\n",
    "sequence of data transforms to be chained together culminating in a modeling process that can\n",
    "be evaluated.\n",
    "\n",
    "The goal is to ensure that all of the steps in the pipeline are constrained to the data available\n",
    "for the evaluation, such as the training dataset or each fold of the cross-validation procedure.\n",
    "You can learn more about Pipelines in scikit-learn by reading the Pipeline section of the user\n",
    "guide. You can also review the API documentation for the Pipeline and FeatureUnion classes\n",
    "and the pipeline module.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/classes.html#module-sklearn.pipeline\n",
    "\n",
    "\n",
    "## Data Preparation and Modeling Pipeline\n",
    "\n",
    "An easy trap to fall into in applied machine learning is leaking data from your training dataset\n",
    "to your test dataset. To avoid this trap you need a robust test harness with strong separation of training and testing. This includes data preparation. Data preparation is one easy way to leak\n",
    "knowledge of the whole training dataset to the algorithm. For example, **preparing your data\n",
    "using normalization or standardization on the entire training dataset before learning would not\n",
    "be a valid test because the training dataset would have been influenced** by the scale of the data\n",
    "in the test set.\n",
    "\n",
    "Links on Data Linkage:\n",
    "\n",
    "https://insidebigdata.com/2014/11/26/ask-data-scientist-data-leakage/\n",
    "https://www.quora.com/Whats-data-leakage-in-data-science\n",
    "\n",
    "Pipelines help you prevent data leakage in your test harness by ensuring that data preparation\n",
    "like standardization is constrained to each fold of your cross-validation procedure. The example\n",
    "below demonstrates this important data preparation and model evaluation workflow on the\n",
    "Pima Indians onset of diabetes dataset. The pipeline is defined with two steps:\n",
    "\n",
    "1. Standardize the data.\n",
    "2. Learn a Linear Discriminant Analysis model.\n",
    "\n",
    "The pipeline is then evaluated using 10-fold cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sequentially apply a list of transforms and a final estimator\n",
    "# Create a pipeline that standardizes the data then creates a model\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# load data\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "# create pipeline\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('lda', LinearDiscriminantAnalysis()))\n",
    "\n",
    "model = Pipeline(estimators)\n",
    "# evaluate pipeline\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Notice how we create a Python list of steps that are provided to the Pipeline for process\n",
    "the data. Also notice how **the Pipeline itself is treated like an estimator and is evaluated in its\n",
    "entirety by the k-fold cross-validation procedure**. Running the example provides a summary of\n",
    "accuracy of the setup on the dataset\n",
    "\n",
    "## Feature Extraction and Modeling Pipeline\n",
    "Feature extraction is another procedure that is susceptible to data leakage. Like data preparation,\n",
    "**feature extraction procedures must be restricted to the data in your training dataset**. The\n",
    "pipeline provides a handy tool called the FeatureUnion which allows the results of multiple\n",
    "feature selection and extraction procedures to be combined into a larger dataset on which a\n",
    "model can be trained. Importantly, all the feature extraction and the feature union occurs\n",
    "within each fold of the cross-validation procedure. The example below demonstrates the pipeline\n",
    "defined with four steps:\n",
    "\n",
    "1. Feature Extraction with Principal Component Analysis (3 features).\n",
    "2. Feature Extraction with Statistical Selection (6 features).\n",
    "3. Feature Union.\n",
    "4. Learn a Logistic Regression Model.\n",
    "\n",
    "The pipeline is then evaluated using 10-fold cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a pipeline that extracts features from the data then creates a model\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "# load data\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "# create feature union - #Concatenates results of multiple transformer objects.\n",
    "features = []\n",
    "features.append(('pca', PCA(n_components=3)))\n",
    "features.append(('select_best', SelectKBest(k=6)))\n",
    "feature_union = FeatureUnion(features)\n",
    "\n",
    "# create pipeline\n",
    "estimators = []\n",
    "estimators.append(('feature_union', feature_union))\n",
    "estimators.append(('logistic', LogisticRegression()))\n",
    "model = Pipeline(estimators)\n",
    "\n",
    "# evaluate pipeline\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows output of a Pipeline extract and combine features before modeling.\n",
    "\n",
    "\n",
    "Notice how the FeatureUnion is its own Pipeline that in turn is a single step in the final\n",
    "Pipeline used to feed Logistic Regression. **This might get you thinking about how you can start\n",
    "embedding pipelines within pipelines**. Running the example provides a summary of accuracy of\n",
    "the setup on the dataset.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html\n",
    "\n",
    "\n",
    "## Summary\n",
    "In this chapter you discovered the difficulties of data leakage in applied machine learning. You\n",
    "discovered the Pipeline utilities in Python scikit-learn and how they can be used to automate\n",
    "standard applied machine learning workflows. You learned how to use Pipelines in two important\n",
    "use cases:\n",
    "- Data preparation and modeling constrained to each fold of the cross-validation procedure.\n",
    "- Feature extraction and feature union constrained to each fold of the cross-validation\n",
    "procedure.\n",
    "\n",
    "\n",
    "### Next\n",
    "This completes the lessons on how to evaluate machine learning algorithms. In the next lesson\n",
    "you will take your first look at how to improve algorithm performance on your problems by\n",
    "using ensemble methods.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the Pima Indian Dataset \n",
    "\n",
    "#### Attribute Information:\n",
    "\n",
    "1. Number of times pregnant \n",
    "2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test \n",
    "3. Diastolic blood pressure (mm Hg) \n",
    "4. Triceps skin fold thickness (mm) \n",
    "5. 2-Hour serum insulin (mu U/ml) \n",
    "6. Body mass index (weight in kg/(height in m)^2) \n",
    "7. Diabetes pedigree function \n",
    "8. Age (years) \n",
    "9. Class variable (0 or 1) "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
